{"version":3,"sources":["../../src/Service/CrawlService.js"],"names":["CrawlService","Service","start","urlsRepository","JsonUrlsRepository","getPathJsonUrlsFile","htmlRepository","HtmlRepository","getProjectPath","headersRepository","HeadersRepository","crawlerRepository","CrawlerRepository","args","option","crawlStatesRepository","SqliteCrawlStatesRepository","initUrl","getSingleUrl","isSingle","initUrlsPool","findAllUrls","progress","emitProgress","html","url","save","then","headers","urls","emitComplete"],"mappings":";;;;;;;AACA;;AACA;;AACA;;AACA;;AACA;;AAEA;;AACA;;;;AAEA;;;AAGe,MAAMA,YAAN,SAA2BC,gBAA3B,CAAmC;AAC9C;;;AAGAC,EAAAA,KAAK,GAAG;AACJ,QAAIC,cAAc,GAAG,IAAIC,2BAAJ,CAAuB,KAAKC,mBAAL,EAAvB,CAArB;AACA,QAAIC,cAAc,GAAG,IAAIC,uBAAJ,CAAmB,KAAKC,cAAL,EAAnB,CAArB;AACA,QAAIC,iBAAiB,GAAG,IAAIC,0BAAJ,CAAsB,KAAKF,cAAL,EAAtB,CAAxB;AACA,QAAIG,iBAAiB,GAAG,IAAIC,0BAAJ,CAAsB,KAAKC,IAA3B,EAAiC,KAAKC,MAAtC,EAA8C,KAAKN,cAAL,EAA9C,CAAxB;AAEA,QAAIO,qBAAqB,GAAG,IAAIC,oCAAJ,CACxB,KAAKR,cAAL,EADwB,CAA5B;AAGAG,IAAAA,iBAAiB,CAACI,qBAAlB,GAA0CA,qBAA1C;AAEA,UAAME,OAAO,GAAG,KAAKJ,IAAL,CAAUK,YAAV,EAAhB;;AACA,QAAI,KAAKL,IAAL,CAAUM,QAAV,MAAwBF,OAAO,IAAI,IAAvC,EAA6C;AACzCF,MAAAA,qBAAqB,CAACK,YAAtB,CAAmC,CAACH,OAAD,CAAnC;AACH;;AACDN,IAAAA,iBAAiB,CACZU,WADL,CACkBC,QAAD,IAAwB;AACjC,WAAKC,YAAL,CAAkBD,QAAlB;;AACA,UAAI,KAAKT,IAAL,CAAUW,IAAV,IAAkBF,QAAQ,CAACG,GAAT,IAAgB,IAAlC,IAA0CH,QAAQ,CAACE,IAAT,IAAiB,IAA/D,EAAqE;AACjElB,QAAAA,cAAc,CAACoB,IAAf,CAAoBJ,QAAQ,CAACG,GAA7B,EAAkCH,QAAQ,CAACE,IAA3C,EAAiDG,IAAjD;AACH;;AACD,UAAI,KAAKd,IAAL,CAAUe,OAAV,IAAqBN,QAAQ,CAACG,GAAT,IAAgB,IAArC,IAA6CH,QAAQ,CAACM,OAAT,IAAoB,IAArE,EAA2E;AACvEnB,QAAAA,iBAAiB,CAACiB,IAAlB,CAAuBJ,QAAQ,CAACG,GAAhC,EAAqCH,QAAQ,CAACM,OAA9C,EAAuDD,IAAvD;AACH;AACJ,KATL,EAUKA,IAVL,CAUUE,IAAI,IAAI;AACV1B,MAAAA,cAAc,CAACuB,IAAf,CAAoBG,IAApB,EAA0BF,IAA1B,CAA+B,MAAM,KAAKG,YAAL,EAArC;AACH,KAZL;AAaH;;AAhC6C","sourcesContent":["// @flow\nimport Service from \"./Service.js\";\nimport Progress from \"../Model/Progress.js\";\nimport JsonUrlsRepository from \"../Repository/JsonUrlsRepository.js\";\nimport CrawlerRepository from \"../Repository/CrawlerRepository.js\";\nimport HtmlRepository from \"../Repository/HtmlRepository.js\";\n\nimport SqliteCrawlStatesRepository from \"../Repository/SqliteCrawlStatesRepository.js\";\nimport HeadersRepository from \"../Repository/HeadersRepository.js\";\n\n/**\n * This service will extract all the urls from a domain by crawling a site.\n */\nexport default class CrawlService extends Service {\n    /**\n     * Start the crawl service to extract the domain urls.\n     */\n    start() {\n        let urlsRepository = new JsonUrlsRepository(this.getPathJsonUrlsFile());\n        let htmlRepository = new HtmlRepository(this.getProjectPath());\n        let headersRepository = new HeadersRepository(this.getProjectPath());\n        let crawlerRepository = new CrawlerRepository(this.args, this.option, this.getProjectPath());\n\n        let crawlStatesRepository = new SqliteCrawlStatesRepository(\n            this.getProjectPath()\n        );\n        crawlerRepository.crawlStatesRepository = crawlStatesRepository;\n\n        const initUrl = this.args.getSingleUrl();\n        if (this.args.isSingle() && initUrl != null) {\n            crawlStatesRepository.initUrlsPool([initUrl]);\n        }\n        crawlerRepository\n            .findAllUrls((progress: Progress) => {\n                this.emitProgress(progress);\n                if (this.args.html && progress.url != null && progress.html != null) {\n                    htmlRepository.save(progress.url, progress.html).then();\n                }\n                if (this.args.headers && progress.url != null && progress.headers != null) {\n                    headersRepository.save(progress.url, progress.headers).then();\n                }\n            })\n            .then(urls => {\n                urlsRepository.save(urls).then(() => this.emitComplete());\n            });\n    }\n}\n"],"file":"CrawlService.js"}