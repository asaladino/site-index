{"version":3,"sources":["../../src/Service/CrawlService.js"],"names":["CrawlService","Service","start","urlsRepository","JsonUrlsRepository","getPathJsonUrlsFile","htmlRepository","HtmlRepository","getProjectPath","crawlerRepository","CrawlerRepository","args","option","crawlStatesRepository","SqliteCrawlStatesRepository","isSingle","initUrlsPool","getSingleUrl","findAllUrls","progress","emitProgress","html","save","url","then","urls","emitComplete"],"mappings":";;;;;;;AAAA;;AACA;;AACA;;AACA;;AACA;;AAEA;;;;AAEA;;;AAGe,MAAMA,YAAN,SAA2BC,gBAA3B,CAAmC;AAChD;;;AAGAC,EAAAA,KAAK,GAAG;AACN,QAAIC,cAAc,GAAG,IAAIC,2BAAJ,CAAuB,KAAKC,mBAAL,EAAvB,CAArB;AACA,QAAIC,cAAc,GAAG,IAAIC,uBAAJ,CAAmB,KAAKC,cAAL,EAAnB,CAArB;AACA,QAAIC,iBAAiB,GAAG,IAAIC,0BAAJ,CAAsB,KAAKC,IAA3B,EAAiC,KAAKC,MAAtC,CAAxB;AAEA,QAAIC,qBAAqB,GAAG,IAAIC,oCAAJ,CAC1B,KAAKN,cAAL,EAD0B,CAA5B;AAGAC,IAAAA,iBAAiB,CAACI,qBAAlB,GAA0CA,qBAA1C;;AAEA,QAAI,KAAKF,IAAL,CAAUI,QAAV,EAAJ,EAA0B;AACxBN,MAAAA,iBAAiB,CAACO,YAAlB,CAA+B,CAAC,KAAKL,IAAL,CAAUM,YAAV,EAAD,CAA/B;AACD;;AACDR,IAAAA,iBAAiB,CACdS,WADH;AAEI;AAAwBC,IAAAA,QAAQ,IAAI;AAClC,WAAKC,YAAL,CAAkBD,QAAlB;;AACA,UAAI,KAAKR,IAAL,CAAUU,IAAd,EAAoB;AAClBf,QAAAA,cAAc,CAACgB,IAAf,CAAoBH,QAAQ,CAACI,GAA7B,EAAkCJ,QAAQ,CAACE,IAA3C,EAAiDG,IAAjD;AACD;AACF,KAPL,EASGA,IATH,CASQC,IAAI,IAAI;AACZtB,MAAAA,cAAc,CAACmB,IAAf,CAAoBG,IAApB,EAA0BD,IAA1B,CAA+B,MAAM,KAAKE,YAAL,EAArC;AACD,KAXH;AAYD;;AA7B+C","sourcesContent":["import Service from \"./Service\";\r\nimport Progress from \"../Model/Progress\";\r\nimport JsonUrlsRepository from \"../Repository/JsonUrlsRepository\";\r\nimport CrawlerRepository from \"../Repository/CrawlerRepository\";\r\nimport HtmlRepository from \"../Repository/HtmlRepository\";\r\n\r\nimport SqliteCrawlStatesRepository from \"../Repository/SqliteCrawlStatesRepository\";\r\n\r\n/**\r\n * This service will extract all the urls from a domain by crawling a site.\r\n */\r\nexport default class CrawlService extends Service {\r\n  /**\r\n   * Start the crawl service to extract the domain urls.\r\n   */\r\n  start() {\r\n    let urlsRepository = new JsonUrlsRepository(this.getPathJsonUrlsFile());\r\n    let htmlRepository = new HtmlRepository(this.getProjectPath());\r\n    let crawlerRepository = new CrawlerRepository(this.args, this.option);\r\n\r\n    let crawlStatesRepository = new SqliteCrawlStatesRepository(\r\n      this.getProjectPath()\r\n    );\r\n    crawlerRepository.crawlStatesRepository = crawlStatesRepository;\r\n\r\n    if (this.args.isSingle()) {\r\n      crawlerRepository.initUrlsPool([this.args.getSingleUrl()]);\r\n    }\r\n    crawlerRepository\r\n      .findAllUrls(\r\n        /** @type {Progress} */ progress => {\r\n          this.emitProgress(progress);\r\n          if (this.args.html) {\r\n            htmlRepository.save(progress.url, progress.html).then();\r\n          }\r\n        }\r\n      )\r\n      .then(urls => {\r\n        urlsRepository.save(urls).then(() => this.emitComplete());\r\n      });\r\n  }\r\n}\r\n"],"file":"CrawlService.js"}