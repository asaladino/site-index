{"version":3,"sources":["../../src/Service/CrawlService.js"],"names":["CrawlService","Service","start","urlsRepository","JsonUrlsRepository","getPathJsonUrlsFile","htmlRepository","HtmlRepository","getProjectPath","crawlerRepository","CrawlerRepository","args","option","crawlStatesRepository","SqliteCrawlStatesRepository","initUrl","getSingleUrl","isSingle","initUrlsPool","findAllUrls","progress","emitProgress","html","url","save","then","urls","emitComplete"],"mappings":"6FACA,0DACA,mEACA,4FACA,0FACA,oFAEA,8G,kFAEA;;GAGe,KAAMA,CAAAA,YAAN,QAA2BC,iBAAQ,CAC9C;;OAGAC,KAAK,EAAG,CACJ,GAAIC,CAAAA,cAAc,CAAG,GAAIC,4BAAJ,CAAuB,KAAKC,mBAAL,EAAvB,CAArB,CACA,GAAIC,CAAAA,cAAc,CAAG,GAAIC,wBAAJ,CAAmB,KAAKC,cAAL,EAAnB,CAArB,CACA,GAAIC,CAAAA,iBAAiB,CAAG,GAAIC,2BAAJ,CAAsB,KAAKC,IAA3B,CAAiC,KAAKC,MAAtC,CAAxB,CAEA,GAAIC,CAAAA,qBAAqB,CAAG,GAAIC,qCAAJ,CACxB,KAAKN,cAAL,EADwB,CAA5B,CAGAC,iBAAiB,CAACI,qBAAlB,CAA0CA,qBAA1C,CAEA,KAAME,CAAAA,OAAO,CAAG,KAAKJ,IAAL,CAAUK,YAAV,EAAhB,CACA,GAAI,KAAKL,IAAL,CAAUM,QAAV,IAAwBF,OAAO,EAAI,IAAvC,CAA6C,CACzCF,qBAAqB,CAACK,YAAtB,CAAmC,CAACH,OAAD,CAAnC,CACH,CACDN,iBAAiB,CACZU,WADL,CACkBC,QAAD,EAAwB,CACjC,KAAKC,YAAL,CAAkBD,QAAlB,EACA,GAAI,KAAKT,IAAL,CAAUW,IAAV,EAAkBF,QAAQ,CAACG,GAAT,EAAgB,IAAlC,EAA0CH,QAAQ,CAACE,IAAT,EAAiB,IAA/D,CAAqE,CACjEhB,cAAc,CAACkB,IAAf,CAAoBJ,QAAQ,CAACG,GAA7B,CAAkCH,QAAQ,CAACE,IAA3C,EAAiDG,IAAjD,EACH,CACJ,CANL,EAOKA,IAPL,CAOUC,IAAI,EAAI,CACVvB,cAAc,CAACqB,IAAf,CAAoBE,IAApB,EAA0BD,IAA1B,CAA+B,IAAM,KAAKE,YAAL,EAArC,CACH,CATL,CAUH,CA5B6C,C","sourcesContent":["// @flow\r\nimport Service from \"./Service\";\r\nimport Progress from \"../Model/Progress\";\r\nimport JsonUrlsRepository from \"../Repository/JsonUrlsRepository\";\r\nimport CrawlerRepository from \"../Repository/CrawlerRepository\";\r\nimport HtmlRepository from \"../Repository/HtmlRepository\";\r\n\r\nimport SqliteCrawlStatesRepository from \"../Repository/SqliteCrawlStatesRepository\";\r\n\r\n/**\r\n * This service will extract all the urls from a domain by crawling a site.\r\n */\r\nexport default class CrawlService extends Service {\r\n    /**\r\n     * Start the crawl service to extract the domain urls.\r\n     */\r\n    start() {\r\n        let urlsRepository = new JsonUrlsRepository(this.getPathJsonUrlsFile());\r\n        let htmlRepository = new HtmlRepository(this.getProjectPath());\r\n        let crawlerRepository = new CrawlerRepository(this.args, this.option);\r\n\r\n        let crawlStatesRepository = new SqliteCrawlStatesRepository(\r\n            this.getProjectPath()\r\n        );\r\n        crawlerRepository.crawlStatesRepository = crawlStatesRepository;\r\n\r\n        const initUrl = this.args.getSingleUrl();\r\n        if (this.args.isSingle() && initUrl != null) {\r\n            crawlStatesRepository.initUrlsPool([initUrl]);\r\n        }\r\n        crawlerRepository\r\n            .findAllUrls((progress: Progress) => {\r\n                this.emitProgress(progress);\r\n                if (this.args.html && progress.url != null && progress.html != null) {\r\n                    htmlRepository.save(progress.url, progress.html).then();\r\n                }\r\n            })\r\n            .then(urls => {\r\n                urlsRepository.save(urls).then(() => this.emitComplete());\r\n            });\r\n    }\r\n}\r\n"],"file":"CrawlService.js"}